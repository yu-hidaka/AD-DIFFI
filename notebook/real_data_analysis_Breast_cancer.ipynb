{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1JsqqdpgqxcUPgzOQVCbS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yu-hidaka/AD-DIFFI/blob/main/real_data_analysis_Breast_cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# Real Data Analysis: Breast Cancer (Table S2)\n",
        "# Comparison of Original DIFFI vs AD-DIFFI (RSO + Z-normalization)\n",
        "# For Google Colab Execution\n",
        "# ============================================================================\n",
        "\n",
        "# =============================================================================\n",
        "# Cell 1: Setup and Install Dependencies\n",
        "# =============================================================================\n",
        "\n",
        "!pip install -q kaggle scikit-learn pandas numpy matplotlib seaborn scipy lifelines\n",
        "print(\"All dependencies installed.\")\n",
        "\n",
        "# =============================================================================\n",
        "# Cell 2: Data Setup Function for Colab\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "def setup_colab_data():\n",
        "    \"\"\"\n",
        "    Automatic data download for Colab environment.\n",
        "\n",
        "    Supports two methods:\n",
        "    1. Kaggle API: Download from Kaggle directly\n",
        "    2. Google Drive: Manual upload to Drive\n",
        "\n",
        "    Returns:\n",
        "        str: Path to Breast_Cancer.csv file\n",
        "    \"\"\"\n",
        "    data_dir = Path('/tmp/ad_diffi_data')\n",
        "    data_dir.mkdir(exist_ok=True)\n",
        "    csv_file = data_dir / 'Breast_Cancer.csv'\n",
        "\n",
        "    # Check if dataset already exists\n",
        "    if csv_file.exists():\n",
        "        print(\"[INFO] Dataset already downloaded at {}\".format(csv_file))\n",
        "        return str(csv_file)\n",
        "\n",
        "    print(\"Downloading Breast Cancer dataset from Kaggle...\")\n",
        "    print(\"\\n[SETUP INSTRUCTIONS]\")\n",
        "    print(\"1. Visit: https://www.kaggle.com/settings/account\")\n",
        "    print(\"2. Click 'Create New API Token'\")\n",
        "    print(\"3. Download kaggle.json\")\n",
        "    print(\"4. Upload the file when prompted below\\n\")\n",
        "\n",
        "    # File upload dialog\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if 'kaggle.json' not in uploaded:\n",
        "        print(\"[ERROR] kaggle.json not found\")\n",
        "        return None\n",
        "\n",
        "    # Configure Kaggle\n",
        "    import subprocess\n",
        "    subprocess.run(['pip', 'install', '-q', 'kaggle'], check=True)\n",
        "    subprocess.run(['mkdir', '-p', str(Path.home() / '.kaggle')], check=True)\n",
        "    subprocess.run(['mv', 'kaggle.json', str(Path.home() / '.kaggle' / 'kaggle.json')], check=True)\n",
        "    subprocess.run(['chmod', '600', str(Path.home() / '.kaggle' / 'kaggle.json')], check=True)\n",
        "\n",
        "    # Download dataset (修正後)\n",
        "    print(\"\\nDownloading...\")\n",
        "    !kaggle datasets download -d reihanenamdari/breast-cancer -p {str(data_dir)} --unzip --force\n",
        "\n",
        "    if csv_file.exists():\n",
        "        print(\"[SUCCESS] Dataset saved to: {}\".format(csv_file))\n",
        "        return str(csv_file)\n",
        "    else:\n",
        "        print(\"[ERROR] Download failed. Check dataset slug or internet.\")\n",
        "        print(\"Alternative: Manual download from https://www.kaggle.com/datasets/reihanenamdari/breast-cancer\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Cell 3: Core Functions - Original DIFFI Implementation\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "from math import ceil\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from typing import Tuple\n",
        "\n",
        "def _get_iic(estimator, predictions, is_leaves, adjust_iic: bool = True) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Compute Induced Imbalance Coefficient (IIC).\n",
        "\n",
        "    Args:\n",
        "        estimator: Fitted isolation tree estimator\n",
        "        predictions: Input samples\n",
        "        is_leaves: Boolean array marking leaf nodes\n",
        "        adjust_iic: Whether to normalize IIC to [0.5, 1.0]\n",
        "\n",
        "    Returns:\n",
        "        lambda_: IIC values for each node\n",
        "    \"\"\"\n",
        "    desired_min = 0.5\n",
        "    desired_max = 1.0\n",
        "    epsilon = 0.0\n",
        "\n",
        "    n_nodes = estimator.tree_.node_count\n",
        "    lambda_ = np.zeros(n_nodes)\n",
        "    children_left = estimator.tree_.children_left\n",
        "    children_right = estimator.tree_.children_right\n",
        "\n",
        "    if predictions.shape[0] == 0:\n",
        "        return lambda_\n",
        "\n",
        "    # Compute sample counts in each node\n",
        "    node_indicator = estimator.decision_path(predictions).toarray()\n",
        "    num_samples_in_node = np.sum(node_indicator, axis=0)\n",
        "\n",
        "    for node in range(n_nodes):\n",
        "        num_samples_current = num_samples_in_node[node]\n",
        "        num_samples_left = num_samples_in_node[children_left[node]]\n",
        "        num_samples_right = num_samples_in_node[children_right[node]]\n",
        "\n",
        "        if num_samples_current <= 1 or is_leaves[node]:\n",
        "            lambda_[node] = -1\n",
        "        elif num_samples_left == 0 or num_samples_right == 0:\n",
        "            lambda_[node] = epsilon\n",
        "        else:\n",
        "            # Compute imbalance ratio\n",
        "            if num_samples_current % 2 == 0:\n",
        "                current_min = 0.5\n",
        "            else:\n",
        "                current_min = ceil(num_samples_current / 2) / num_samples_current\n",
        "            current_max = (num_samples_current - 1) / num_samples_current\n",
        "            max_child_ratio = max(num_samples_left, num_samples_right) / num_samples_current\n",
        "\n",
        "            if adjust_iic and current_min != current_max:\n",
        "                lambda_[node] = ((max_child_ratio - current_min) / (current_max - current_min)) \\\n",
        "                               * (desired_max - desired_min) + desired_min\n",
        "            else:\n",
        "                lambda_[node] = max_child_ratio\n",
        "\n",
        "    return lambda_\n",
        "\n",
        "\n",
        "def diffi_ib(iforest: IsolationForest, X: np.ndarray, adjust_iic: bool = True) -> Tuple[np.ndarray, float]:\n",
        "    \"\"\"\n",
        "    Original DIFFI: Depth-based Isolation Forest Feature Importance.\n",
        "\n",
        "    Args:\n",
        "        iforest: Fitted IsolationForest model\n",
        "        X: Input data (n_samples, n_features)\n",
        "        adjust_iic: Whether to adjust IIC scaling\n",
        "\n",
        "    Returns:\n",
        "        fi_ib: Feature importance scores (n_features,)\n",
        "        exec_time: Computation time in seconds\n",
        "    \"\"\"\n",
        "    start = time.time()\n",
        "    num_features = X.shape[1]\n",
        "    estimators = iforest.estimators_\n",
        "    in_bag_samples = iforest.estimators_samples_\n",
        "\n",
        "    # Initialize accumulators\n",
        "    cfi_outliers = np.zeros(num_features, dtype=float)\n",
        "    cfi_inliers = np.zeros(num_features, dtype=float)\n",
        "    cnt_outliers = np.zeros(num_features, dtype=int)\n",
        "    cnt_inliers = np.zeros(num_features, dtype=int)\n",
        "\n",
        "    # Compute anomaly threshold\n",
        "    global_scores = iforest.decision_function(X)\n",
        "    threshold = np.percentile(global_scores, 100 * iforest.contamination)\n",
        "\n",
        "    for k, estimator in enumerate(estimators):\n",
        "        in_bag_index = list(in_bag_samples[k])\n",
        "        X_ib = X[in_bag_index, :]\n",
        "        scores_ib = global_scores[in_bag_index]\n",
        "\n",
        "        X_outliers = X_ib[scores_ib < threshold]\n",
        "        X_inliers = X_ib[scores_ib >= threshold]\n",
        "\n",
        "        if X_inliers.shape[0] == 0 or X_outliers.shape[0] == 0:\n",
        "            continue\n",
        "\n",
        "        # Extract tree structure\n",
        "        tree = estimator.tree_\n",
        "        n_nodes = tree.node_count\n",
        "        children_left = tree.children_left\n",
        "        children_right = tree.children_right\n",
        "        feature = tree.feature\n",
        "\n",
        "        # Compute node depths\n",
        "        node_depth = np.zeros(n_nodes, dtype=np.int64)\n",
        "        is_leaves = np.zeros(n_nodes, dtype=bool)\n",
        "\n",
        "        stack = [(0, 0)]\n",
        "        while stack:\n",
        "            node_id, depth = stack.pop()\n",
        "            node_depth[node_id] = depth\n",
        "            if children_left[node_id] != children_right[node_id]:\n",
        "                stack.append((children_left[node_id], depth + 1))\n",
        "                stack.append((children_right[node_id], depth + 1))\n",
        "            else:\n",
        "                is_leaves[node_id] = True\n",
        "\n",
        "        # Process outliers\n",
        "        lambda_outliers = _get_iic(estimator, X_outliers, is_leaves, adjust_iic)\n",
        "        node_indicator_outliers = estimator.decision_path(X_outliers).toarray()\n",
        "\n",
        "        for i in range(len(X_outliers)):\n",
        "            path = np.where(node_indicator_outliers[i] == 1)[0]\n",
        "            if len(path) == 0:\n",
        "                continue\n",
        "            depth = node_depth[path[-1]]\n",
        "            for node in path:\n",
        "                current_feature = feature[node]\n",
        "                if current_feature >= 0 and lambda_outliers[node] != -1:\n",
        "                    cfi_outliers[current_feature] += (1.0 / depth) * lambda_outliers[node]\n",
        "                    cnt_outliers[current_feature] += 1\n",
        "\n",
        "        # Process inliers\n",
        "        lambda_inliers = _get_iic(estimator, X_inliers, is_leaves, adjust_iic)\n",
        "        node_indicator_inliers = estimator.decision_path(X_inliers).toarray()\n",
        "\n",
        "        for i in range(len(X_inliers)):\n",
        "            path = np.where(node_indicator_inliers[i] == 1)[0]\n",
        "            if len(path) == 0:\n",
        "                continue\n",
        "            depth = node_depth[path[-1]]\n",
        "            for node in path:\n",
        "                current_feature = feature[node]\n",
        "                if current_feature >= 0 and lambda_inliers[node] != -1:\n",
        "                    cfi_inliers[current_feature] += (1.0 / depth) * lambda_inliers[node]\n",
        "                    cnt_inliers[current_feature] += 1\n",
        "\n",
        "    # Normalize and compute ratio\n",
        "    fi_outliers = np.where(cnt_outliers > 0, cfi_outliers / cnt_outliers, 0)\n",
        "    fi_inliers = np.where(cnt_inliers > 0, cfi_inliers / cnt_inliers, 0)\n",
        "\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        fi_ib = np.divide(fi_outliers, fi_inliers, out=np.zeros_like(fi_outliers),\n",
        "                         where=fi_inliers != 0)\n",
        "\n",
        "    exec_time = time.time() - start\n",
        "    return fi_ib, exec_time\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Cell 4: AD-DIFFI Implementation (RSO + Z-normalization)\n",
        "# =============================================================================\n",
        "\n",
        "from typing import Dict, Tuple\n",
        "\n",
        "MIN_DEPTH = 1\n",
        "\n",
        "def diffi_ib_binary_rso(\n",
        "    iforest: IsolationForest,\n",
        "    X_data: np.ndarray,\n",
        "    feature_types: Dict[int, str]\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    AD-DIFFI with Root-Split-Only (RSO) constraint for binary features.\n",
        "\n",
        "    Args:\n",
        "        iforest: Fitted IsolationForest model\n",
        "        X_data: Input data (n_samples, n_features)\n",
        "        feature_types: Dict mapping feature index to 'cont' or 'bin'\n",
        "\n",
        "    Returns:\n",
        "        fi_rso: Feature importance scores with RSO constraint\n",
        "    \"\"\"\n",
        "    num_features = X_data.shape[1]\n",
        "    estimators = iforest.estimators_\n",
        "\n",
        "    cfi_outliers = np.zeros(num_features, dtype=float)\n",
        "    cfi_inliers = np.zeros(num_features, dtype=float)\n",
        "    cnt_outliers = np.zeros(num_features, dtype=int)\n",
        "    cnt_inliers = np.zeros(num_features, dtype=int)\n",
        "\n",
        "    # Compute anomaly threshold\n",
        "    global_scores = iforest.decision_function(X_data)\n",
        "    threshold = np.percentile(global_scores, 100 * iforest.contamination)\n",
        "\n",
        "    for k, estimator in enumerate(estimators):\n",
        "        in_bag_index = iforest.estimators_samples_[k]\n",
        "        X_ib = X_data[in_bag_index]\n",
        "        scores_ib = global_scores[in_bag_index]\n",
        "\n",
        "        X_outliers = X_ib[scores_ib < threshold]\n",
        "        X_inliers = X_ib[scores_ib >= threshold]\n",
        "\n",
        "        if X_outliers.shape[0] == 0 or X_inliers.shape[0] == 0:\n",
        "            continue\n",
        "\n",
        "        # Extract tree structure\n",
        "        tree = estimator.tree_\n",
        "        n_nodes = tree.node_count\n",
        "        children_left = tree.children_left\n",
        "        children_right = tree.children_right\n",
        "        feature_index = tree.feature\n",
        "        n_node_samples = tree.n_node_samples\n",
        "\n",
        "        # Compute node depths\n",
        "        node_depth = np.zeros(n_nodes, dtype=int)\n",
        "        stack = [(0, 0)]\n",
        "        while stack:\n",
        "            node_id, depth = stack.pop()\n",
        "            node_depth[node_id] = depth\n",
        "            if children_left[node_id] != children_right[node_id]:\n",
        "                stack.append((children_left[node_id], depth + 1))\n",
        "                stack.append((children_right[node_id], depth + 1))\n",
        "\n",
        "        # Compute adjusted lambda (imbalance coefficient)\n",
        "        lambda_adjusted = np.zeros(n_nodes, dtype=float)\n",
        "        for node in range(n_nodes):\n",
        "            if children_left[node] != children_right[node]:\n",
        "                n_parent = n_node_samples[node]\n",
        "                n_left = n_node_samples[children_left[node]]\n",
        "                n_right = n_node_samples[children_right[node]]\n",
        "                ratio_small = min(n_left, n_right) / n_parent\n",
        "                lambda_adjusted[node] = 1.0 - ratio_small\n",
        "\n",
        "        def accumulate_contributions(X_subset, cfi, cnt):\n",
        "            \"\"\"Accumulate feature importance contributions from samples.\"\"\"\n",
        "            node_indicator = estimator.decision_path(X_subset).toarray()\n",
        "            for sample_idx in range(X_subset.shape[0]):\n",
        "                path = np.where(node_indicator[sample_idx] == 1)[0]\n",
        "                if len(path) == 0:\n",
        "                    continue\n",
        "\n",
        "                depth_leaf = node_depth[path[-1]]\n",
        "                h_leaf = max(depth_leaf, MIN_DEPTH)\n",
        "                depth_scale = 1.0 / h_leaf\n",
        "\n",
        "                for node in path:\n",
        "                    feat_idx = feature_index[node]\n",
        "                    if feat_idx < 0:\n",
        "                        continue\n",
        "\n",
        "                    feature_type = feature_types[feat_idx]\n",
        "                    # RSO constraint: binary features only split at root (depth=0)\n",
        "                    if feature_type == 'bin' and node_depth[node] > 0:\n",
        "                        continue\n",
        "\n",
        "                    contribution = depth_scale * lambda_adjusted[node]\n",
        "                    cfi[feat_idx] += contribution\n",
        "                    cnt[feat_idx] += 1\n",
        "\n",
        "        accumulate_contributions(X_outliers, cfi_outliers, cnt_outliers)\n",
        "        accumulate_contributions(X_inliers, cfi_inliers, cnt_inliers)\n",
        "\n",
        "    # Normalize and compute ratio\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        fi_outliers = np.where(cnt_outliers > 0, cfi_outliers / cnt_outliers, 0)\n",
        "        fi_inliers = np.where(cnt_inliers > 0, cfi_inliers / cnt_inliers, 0)\n",
        "        fi_rso = np.divide(fi_outliers, fi_inliers, out=np.zeros_like(fi_outliers),\n",
        "                          where=fi_inliers != 0)\n",
        "\n",
        "    return fi_rso\n",
        "\n",
        "\n",
        "def noise_baseline_rso(\n",
        "    X_dim: int,\n",
        "    feature_types: Dict[int, str],\n",
        "    if_params: Dict,\n",
        "    n_iter: int = 50\n",
        ") -> Tuple[float, float, float, float]:\n",
        "    \"\"\"\n",
        "    Establish noise baseline for RSO-based DIFFI scores.\n",
        "\n",
        "    Uses random uniform noise to determine null distribution.\n",
        "\n",
        "    Args:\n",
        "        X_dim: Number of features\n",
        "        feature_types: Dict mapping feature index to 'cont' or 'bin'\n",
        "        if_params: Isolation Forest hyperparameters\n",
        "        n_iter: Number of iterations\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (cont_mean, cont_sd, bin_mean, bin_sd)\n",
        "    \"\"\"\n",
        "    print(\"Establishing noise baseline (RSO DIFFI) over {} iterations...\".format(n_iter))\n",
        "    scores_list = []\n",
        "\n",
        "    cont_indices = [i for i, t in feature_types.items() if t == 'cont']\n",
        "    bin_indices = [i for i, t in feature_types.items() if t == 'bin']\n",
        "\n",
        "    for k in range(n_iter):\n",
        "        X_noise = np.random.uniform(0, 1, size=(2000, X_dim))\n",
        "        iforest = IsolationForest(random_state=k, **if_params)\n",
        "        iforest.fit(X_noise)\n",
        "        fi = diffi_ib_binary_rso(iforest, X_noise, feature_types)\n",
        "        scores_list.append(fi)\n",
        "\n",
        "    M = np.vstack(scores_list)\n",
        "\n",
        "    cont_scores = M[:, cont_indices] if cont_indices else np.array([])\n",
        "    bin_scores = M[:, bin_indices] if bin_indices else np.array([])\n",
        "\n",
        "    cont_mean = float(cont_scores.mean()) if len(cont_indices) > 0 else 1.0\n",
        "    cont_sd = float(cont_scores.std()) if len(cont_indices) > 0 else 1.0\n",
        "    bin_mean = float(bin_scores.mean()) if len(bin_indices) > 0 else 1.0\n",
        "    bin_sd = float(bin_scores.std()) if len(bin_indices) > 0 else 1.0\n",
        "\n",
        "    print(\"  Continuous (mean={:.4f}, std={:.4f})\".format(cont_mean, cont_sd))\n",
        "    print(\"  Binary      (mean={:.4f}, std={:.4f})\".format(bin_mean, bin_sd))\n",
        "\n",
        "    return cont_mean, cont_sd, bin_mean, bin_sd\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Cell 5: Comparison Function\n",
        "# =============================================================================\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from typing import List\n",
        "\n",
        "def compare_diffi_vs_ad_diffi(\n",
        "    X: np.ndarray,\n",
        "    feature_names: List[str],\n",
        "    feature_types: Dict[int, str],\n",
        "    if_params: Dict,\n",
        "    n_iter_noise: int = 50,\n",
        "    n_iter_main: int = 50,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Compare Original DIFFI vs AD-DIFFI (RSO + Z-normalization).\n",
        "\n",
        "    Args:\n",
        "        X: Feature matrix (n_samples, n_features)\n",
        "        feature_names: List of feature names\n",
        "        feature_types: Dict mapping feature index to 'cont' or 'bin'\n",
        "        if_params: Isolation Forest parameters\n",
        "        n_iter_noise: Iterations for noise baseline\n",
        "        n_iter_main: Iterations for main comparison\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with importance scores, ranks and rank changes\n",
        "    \"\"\"\n",
        "    # Standardize data\n",
        "    X_scaled = StandardScaler().fit_transform(X)\n",
        "\n",
        "    # Establish noise baseline for AD-DIFFI\n",
        "    cont_mean, cont_sd, bin_mean, bin_sd = noise_baseline_rso(\n",
        "        X_dim=X_scaled.shape[1],\n",
        "        feature_types=feature_types,\n",
        "        if_params=if_params,\n",
        "        n_iter=n_iter_noise\n",
        "    )\n",
        "\n",
        "    # Run main comparison iterations\n",
        "    orig_scores_list = []\n",
        "    rso_raw_list = []\n",
        "\n",
        "    print(\"Running {} iterations for feature importance comparison...\".format(n_iter_main))\n",
        "    for k in range(n_iter_main):\n",
        "        iforest = IsolationForest(random_state=k, **if_params)\n",
        "        iforest.fit(X_scaled)\n",
        "\n",
        "        # Original DIFFI\n",
        "        fi_orig, _ = diffi_ib(iforest, X_scaled, adjust_iic=True)\n",
        "        orig_scores_list.append(fi_orig)\n",
        "\n",
        "        # AD-DIFFI RSO (raw)\n",
        "        fi_rso = diffi_ib_binary_rso(iforest, X_scaled, feature_types)\n",
        "        rso_raw_list.append(fi_rso)\n",
        "\n",
        "    mean_orig = np.mean(orig_scores_list, axis=0)\n",
        "    M_rso_raw = np.vstack(rso_raw_list)\n",
        "\n",
        "    # Z-normalize RSO scores\n",
        "    rso_z_scores = M_rso_raw.copy()\n",
        "    for i in range(len(feature_names)):\n",
        "        if feature_types[i] == 'cont':\n",
        "            if cont_sd > 0:\n",
        "                rso_z_scores[:, i] = (M_rso_raw[:, i] - cont_mean) / cont_sd\n",
        "            else:\n",
        "                rso_z_scores[:, i] = 0.0\n",
        "        else:  # binary\n",
        "            if bin_sd > 0:\n",
        "                rso_z_scores[:, i] = (M_rso_raw[:, i] - bin_mean) / bin_sd\n",
        "            else:\n",
        "                rso_z_scores[:, i] = 0.0\n",
        "\n",
        "    mean_rso_z = np.mean(rso_z_scores, axis=0)\n",
        "\n",
        "    # Build comparison table\n",
        "    compare_df = pd.DataFrame({\n",
        "        \"Feature\": feature_names,\n",
        "        \"Type\": [feature_types[i] for i in range(len(feature_names))],\n",
        "        \"Original_DIFFI\": np.round(mean_orig, 4),\n",
        "        \"AD_DIFFI_RSO_Z\": np.round(mean_rso_z, 4),\n",
        "    })\n",
        "\n",
        "    compare_df[\"Rank_Original\"] = compare_df[\"Original_DIFFI\"].rank(ascending=False)\n",
        "    compare_df[\"Rank_AD_DIFFI\"] = compare_df[\"AD_DIFFI_RSO_Z\"].rank(ascending=False)\n",
        "    compare_df[\"Rank_Change\"] = compare_df[\"Rank_AD_DIFFI\"] - compare_df[\"Rank_Original\"]\n",
        "\n",
        "    return compare_df.sort_values(\"AD_DIFFI_RSO_Z\", ascending=False)\n",
        "\n",
        "# =============================================================================\n",
        "# Cell 6: Breast Cancer Dataset Processing\n",
        "# =============================================================================\n",
        "\n",
        "def create_binary_features_breast_cancer(df: pd.DataFrame) -> pd.DataFrame:\n",
        "\n",
        "    df_processed = df[[\n",
        "        'Age', 'Tumor Size', 'Regional Node Examined',\n",
        "        'Reginol Node Positive', 'Survival Months', 'Status'\n",
        "    ]].copy()\n",
        "\n",
        "    df_processed['Race_White'] = (df['Race'] == 'White').astype(int)\n",
        "    df_processed['Marital_Married'] = df['Marital Status'].isin(\n",
        "        ['Married', 'Married-spouse-absent']\n",
        "    ).astype(int)\n",
        "    df_processed['T_Stage_T1'] = (df['T Stage '] == 'T1').astype(int)\n",
        "    df_processed['N_Stage_N0'] = (df['N Stage'] == 'N0').astype(int)\n",
        "    df_processed['Stage_II'] = (df['6th Stage'] == 'II').astype(int)\n",
        "\n",
        "    diff_map = {\n",
        "        'Poorly differentiated': 0,\n",
        "        'Moderately differentiated': 1,\n",
        "        'Well differentiated': 1,\n",
        "        'Poorly differentiated; Moderately differentiated': 0\n",
        "    }\n",
        "    df_processed['Differentiate_High'] = df['differentiate'].map(diff_map).fillna(1).astype(int)\n",
        "    df_processed['Grade_Low'] = df['Grade'].isin(['Grade I', 'Grade II']).astype(int)\n",
        "    df_processed['A_Stage_Regional'] = (df['A Stage'] == 'Regional').astype(int)\n",
        "    df_processed['Estrogen_Positive'] = (df['Estrogen Status'] == 'Positive').astype(int)\n",
        "    df_processed['Progesterone_Positive'] = (df['Progesterone Status'] == 'Positive').astype(int)\n",
        "\n",
        "    return df_processed\n",
        "\n",
        "\n",
        "def evaluate_cox_cindex(\n",
        "    df: pd.DataFrame,\n",
        "    feature_list: List[str],\n",
        "    time_col: str = 'Survival Months',\n",
        "    event_col: str = 'Status_num',\n",
        "    random_seed: int = 0,\n",
        "    max_features: int = 10\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Robust Cox C-index with multicollinearity handling.\n",
        "    \"\"\"\n",
        "    from lifelines import CoxPHFitter\n",
        "    from lifelines.utils import concordance_index\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "    np.random.seed(random_seed)\n",
        "\n",
        "    X_raw = df[feature_list].fillna(df[feature_list].median()).copy()\n",
        "    T = df[time_col].values\n",
        "    E = df[event_col].values\n",
        "\n",
        "    valid_mask = ~(pd.isna(T) | pd.isna(E))\n",
        "    if valid_mask.sum() < 20:\n",
        "        print(f\"[WARNING] Insufficient data: {valid_mask.sum()} samples\")\n",
        "        return 0.0\n",
        "\n",
        "    X = X_raw[valid_mask].reset_index(drop=True)\n",
        "    T_valid = T[valid_mask]\n",
        "    E_valid = E[valid_mask]\n",
        "\n",
        "    n_samples, n_features = X.shape\n",
        "    print(f\"[DEBUG] Cox: {n_samples} samples, {n_features} features\")\n",
        "\n",
        "    if n_features == 0:\n",
        "        return 0.0\n",
        "\n",
        "    selector = VarianceThreshold(threshold=0.01)\n",
        "    X_var = selector.fit_transform(X)\n",
        "    selected_features = [feature_list[i] for i in selector.get_support(indices=True)]\n",
        "\n",
        "    if len(selected_features) == 0:\n",
        "        print(\"[WARNING] No features after variance filtering\")\n",
        "        return 0.0\n",
        "\n",
        "    X_filtered = pd.DataFrame(X_var, columns=selected_features)\n",
        "    print(f\"[DEBUG] After variance filter: {len(selected_features)} features\")\n",
        "\n",
        "    if len(selected_features) > max_features:\n",
        "        corr_matrix = X_filtered.corr().abs()\n",
        "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "        high_corr = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
        "\n",
        "        remaining_features = [f for f in selected_features if f not in high_corr]\n",
        "        if len(remaining_features) > max_features:\n",
        "            remaining_features = remaining_features[:max_features]\n",
        "\n",
        "        X_filtered = X_filtered[remaining_features]\n",
        "        print(f\"[DEBUG] After correlation filter: {len(remaining_features)} features\")\n",
        "    else:\n",
        "        remaining_features = selected_features\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = pd.DataFrame(\n",
        "        scaler.fit_transform(X_filtered),\n",
        "        columns=remaining_features\n",
        "    )\n",
        "\n",
        "    survival_df = pd.DataFrame({\n",
        "        time_col: T_valid,\n",
        "        'event': E_valid.astype(bool)\n",
        "    })\n",
        "    cox_df = pd.concat([survival_df, X_scaled], axis=1)\n",
        "\n",
        "    try:\n",
        "        cph = CoxPHFitter()\n",
        "        cph.fit(\n",
        "            cox_df,\n",
        "            duration_col=time_col,\n",
        "            event_col='event',\n",
        "            show_progress=False,\n",
        "            robust=True\n",
        "        )\n",
        "\n",
        "        risk_scores = -cph.predict_partial_hazard(X_scaled)\n",
        "        cindex = concordance_index(T_valid, risk_scores, E_valid)\n",
        "\n",
        "        print(f\"[SUCCESS] Cox C-index: {cindex:.4f} ({len(remaining_features)} features)\")\n",
        "        return float(cindex)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Cox failed: {str(e)[:100]}\")\n",
        "        print(\"  Using null model C-index...\")\n",
        "\n",
        "        if len(remaining_features) > 0:\n",
        "            single_feature = remaining_features[0]\n",
        "            single_df = pd.concat([\n",
        "                survival_df,\n",
        "                X_scaled[[single_feature]]\n",
        "            ], axis=1)\n",
        "\n",
        "            try:\n",
        "                cph_single = CoxPHFitter()\n",
        "                cph_single.fit(single_df, duration_col=time_col, event_col='event', show_progress=False)\n",
        "                risk_single = -cph_single.predict_partial_hazard(X_scaled[[single_feature]])\n",
        "                cindex_single = concordance_index(T_valid, risk_single, E_valid)\n",
        "                print(f\"[FALLBACK] Single feature C-index: {cindex_single:.4f}\")\n",
        "                return float(cindex_single)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        return 0.5\n",
        "\n",
        "\n",
        "def evaluate_if_auc(\n",
        "    df: pd.DataFrame,\n",
        "    feature_list: List[str],\n",
        "    y: np.ndarray,\n",
        "    if_params: Dict,\n",
        "    random_state: int = 0\n",
        ") -> float:\n",
        "\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "    X = df[feature_list].fillna(df[feature_list].median()).values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=random_state, stratify=y\n",
        "    )\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_sc = scaler.fit_transform(X_train)\n",
        "    X_test_sc = scaler.transform(X_test)\n",
        "\n",
        "    from sklearn.ensemble import IsolationForest\n",
        "    iforest = IsolationForest(**if_params, random_state=random_state)\n",
        "    iforest.fit(X_train_sc)\n",
        "\n",
        "    scores = -iforest.decision_function(X_test_sc)\n",
        "    auc = roc_auc_score(y_test, scores)\n",
        "    return auc\n",
        "\n",
        "# =============================================================================\n",
        "# Cell 7: Load Data and Run Analysis (Updated with seeds and Cox C-index)\n",
        "# =============================================================================\n",
        "\n",
        "def run_breast_cancer_analysis(random_seed: int = 42):\n",
        "    \"\"\"Main analysis execution with reproducible seeds.\"\"\"\n",
        "\n",
        "    # Set global random seeds for reproducibility\n",
        "    np.random.seed(random_seed)\n",
        "    import random\n",
        "    random.seed(random_seed)\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"AD-DIFFI Real Data Analysis: Breast Cancer (Table S2)\")\n",
        "    print(\"Random Seed: {}\".format(random_seed))\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Data setup\n",
        "    data_path = setup_colab_data()\n",
        "\n",
        "    if not data_path:\n",
        "        print(\"[ERROR] Failed to load dataset\")\n",
        "        return\n",
        "\n",
        "    # Load and process data\n",
        "    df_BC = pd.read_csv(data_path)\n",
        "    df_BC_processed = create_binary_features_breast_cancer(df_BC)\n",
        "\n",
        "    # Feature definitions\n",
        "    feature_cols = [c for c in df_BC_processed.columns\n",
        "                    if c not in ['Status', 'Survival Months']]\n",
        "\n",
        "    print(\"[INFO] Available features:\", feature_cols)\n",
        "\n",
        "    FEATURE_DEFINITIONS = [\n",
        "        {'name': col, 'type': 'bin' if df_BC_processed[col].nunique() <= 10 else 'cont'}\n",
        "        for col in feature_cols\n",
        "    ]\n",
        "    FEATURE_TYPES = {i: f['type'] for i, f in enumerate(FEATURE_DEFINITIONS)}\n",
        "    FEATURE_NAMES = [f['name'] for f in FEATURE_DEFINITIONS]\n",
        "\n",
        "    print(\"[INFO] Dataset: {} samples, {} features\".format(\n",
        "        len(df_BC_processed), len(feature_cols)\n",
        "    ))\n",
        "    n_cont = sum(1 for f in FEATURE_DEFINITIONS if f['type'] == 'cont')\n",
        "    n_bin = sum(1 for f in FEATURE_DEFINITIONS if f['type'] == 'bin')\n",
        "    print(\"[INFO] Feature types: {} continuous, {} binary\".format(n_cont, n_bin))\n",
        "\n",
        "    # Prepare data\n",
        "    X_data = df_BC_processed[feature_cols].fillna(\n",
        "        df_BC_processed[feature_cols].median()\n",
        "    ).values\n",
        "\n",
        "    # Isolation Forest parameters\n",
        "    IF_PARAMS = {\n",
        "        'n_estimators': 200,\n",
        "        'max_samples': 512,\n",
        "        'contamination': 0.05,\n",
        "        'max_features': 1.0,\n",
        "        'bootstrap': False,\n",
        "    }\n",
        "\n",
        "    # Run comparison\n",
        "    print(\"=\"*70)\n",
        "    print(\"Running feature importance comparison...\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    compare_results = compare_diffi_vs_ad_diffi(\n",
        "        X=X_data,\n",
        "        feature_names=FEATURE_NAMES,\n",
        "        feature_types=FEATURE_TYPES,\n",
        "        if_params=IF_PARAMS,\n",
        "        n_iter_noise=20,\n",
        "        n_iter_main=20,\n",
        "    )\n",
        "\n",
        "    print(\"\\nFeature Importance Comparison (Table S2)\")\n",
        "    print(compare_results.to_markdown(index=False))\n",
        "\n",
        "    # Prepare target variables\n",
        "    df_BC_processed[\"Status_num\"] = (df_BC_processed[\"Status\"] != \"Alive\").astype(int)\n",
        "    y_status = df_BC_processed[\"Status_num\"].values\n",
        "\n",
        "    # Evaluate performance metrics\n",
        "    print(\"=\"*70)\n",
        "    print(\"Performance Evaluation (IF AUC + Cox C-index)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # All features\n",
        "    auc_all = evaluate_if_auc(df_BC_processed, feature_cols, y_status, IF_PARAMS, random_seed)\n",
        "    cindex_all = evaluate_cox_cindex(df_BC_processed, feature_cols, random_seed=random_seed)\n",
        "    print(\"All {:2d} features:  IF AUC={:.4f}, Cox C-index={:.4f}\".format(\n",
        "      len(feature_cols), auc_all, cindex_all))\n",
        "\n",
        "    # Original DIFFI top-6\n",
        "    top_orig = compare_results.sort_values(\"Original_DIFFI\", ascending=False).head(6)\n",
        "    top_orig_feats = top_orig[\"Feature\"].tolist()\n",
        "    auc_orig6 = evaluate_if_auc(df_BC_processed, top_orig_feats, y_status, IF_PARAMS, random_seed)\n",
        "    cindex_orig6 = evaluate_cox_cindex(df_BC_processed, top_orig_feats, random_seed=random_seed)\n",
        "    print(\"Original DIFFI top-6: IF AUC={:.4f}, Cox C-index={:.4f}\".format(auc_orig6, cindex_orig6))\n",
        "\n",
        "    # AD-DIFFI top-6\n",
        "    top_ad = compare_results.sort_values(\"AD_DIFFI_RSO_Z\", ascending=False).head(6)\n",
        "    top_ad_feats = top_ad[\"Feature\"].tolist()\n",
        "    auc_ad6 = evaluate_if_auc(df_BC_processed, top_ad_feats, y_status, IF_PARAMS, random_seed)\n",
        "    cindex_ad6 = evaluate_cox_cindex(df_BC_processed, top_ad_feats, random_seed=random_seed)\n",
        "    print(\"AD-DIFFI top-6:     IF AUC={:.4f}, Cox C-index={:.4f}\".format(auc_ad6, cindex_ad6))\n",
        "\n",
        "    # Summary table\n",
        "    print(\"\\nSummary Table:\")\n",
        "    summary_data = {\n",
        "        \"Method\": [\"All Features\", \"Original DIFFI Top-6\", \"AD-DIFFI Top-6\"],\n",
        "        \"IF AUC\": [round(auc_all, 4), round(auc_orig6, 4), round(auc_ad6, 4)],\n",
        "        \"Cox C-index\": [round(cindex_all, 4), round(cindex_orig6, 4), round(cindex_ad6, 4)]\n",
        "    }\n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "    print(summary_df.to_markdown(index=False))\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"Analysis complete.\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Return results for download\n",
        "    results_dict = {\n",
        "        'feature_importance': compare_results,\n",
        "        'performance_summary': summary_df,\n",
        "        'top_orig_features': top_orig_feats,\n",
        "        'top_ad_features': top_ad_feats,\n",
        "        'metrics': {\n",
        "            'all': {'if_auc': auc_all, 'cindex': cindex_all},\n",
        "            'orig_top6': {'if_auc': auc_orig6, 'cindex': cindex_orig6},\n",
        "            'ad_top6': {'if_auc': auc_ad6, 'cindex': cindex_ad6}\n",
        "        }\n",
        "    }\n",
        "    return results_dict\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Cell 8: Download Results (Updated)\n",
        "# =============================================================================\n",
        "\n",
        "def save_and_download_results(results_dict: dict, random_seed: int = 42):\n",
        "    \"\"\"\n",
        "    Save all results and prepare for download.\n",
        "\n",
        "    Args:\n",
        "        results_dict: Dictionary containing all analysis results\n",
        "        random_seed: Random seed used\n",
        "    \"\"\"\n",
        "    import json\n",
        "\n",
        "    # Save feature importance\n",
        "    compare_results = results_dict['feature_importance']\n",
        "    output_filename = f'breast_cancer_analysis_seed{random_seed}.csv'\n",
        "    compare_results.to_csv(output_filename, index=False)\n",
        "\n",
        "    # Save performance summary\n",
        "    summary_df = results_dict['performance_summary']\n",
        "    summary_filename = f'breast_cancer_performance_seed{random_seed}.csv'\n",
        "    summary_df.to_csv(summary_filename, index=False)\n",
        "\n",
        "    # Save detailed metrics\n",
        "    metrics_filename = f'breast_cancer_metrics_seed{random_seed}.json'\n",
        "    with open(metrics_filename, 'w') as f:\n",
        "        json.dump(results_dict['metrics'], f, indent=2)\n",
        "\n",
        "    print(\"[INFO] Files saved:\")\n",
        "    print(f\"  - {output_filename}\")\n",
        "    print(f\"  - {summary_filename}\")\n",
        "    print(f\"  - {metrics_filename}\")\n",
        "\n",
        "    # Download in Colab\n",
        "    from google.colab import files\n",
        "    files.download(output_filename)\n",
        "    files.download(summary_filename)\n",
        "    files.download(metrics_filename)\n",
        "    print(\"[INFO] Downloads started...\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Main Execution (Run in Colab) - Updated with seed control\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run analysis with reproducible seed\n",
        "    RANDOM_SEED = 42  # Change this value to get different reproducible results\n",
        "    results = run_breast_cancer_analysis(random_seed=RANDOM_SEED)\n",
        "\n",
        "    # Save and download results\n",
        "    if results is not None:\n",
        "        save_and_download_results(results, random_seed=RANDOM_SEED)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JSFM-NWvb_1I",
        "outputId": "146ec740-f43d-4e14-931f-e14814bd3daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All dependencies installed.\n",
            "======================================================================\n",
            "AD-DIFFI Real Data Analysis: Breast Cancer (Table S2)\n",
            "Random Seed: 42\n",
            "======================================================================\n",
            "Downloading Breast Cancer dataset from Kaggle...\n",
            "\n",
            "[SETUP INSTRUCTIONS]\n",
            "1. Visit: https://www.kaggle.com/settings/account\n",
            "2. Click 'Create New API Token'\n",
            "3. Download kaggle.json\n",
            "4. Upload the file when prompted below\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-21529b31-ec60-45b4-a966-f03d89aec366\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-21529b31-ec60-45b4-a966-f03d89aec366\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "\n",
            "Downloading...\n",
            "Dataset URL: https://www.kaggle.com/datasets/reihanenamdari/breast-cancer\n",
            "License(s): Attribution 4.0 International (CC BY 4.0)\n",
            "Downloading breast-cancer.zip to /tmp/ad_diffi_data\n",
            "  0% 0.00/42.8k [00:00<?, ?B/s]\n",
            "100% 42.8k/42.8k [00:00<00:00, 126MB/s]\n",
            "[SUCCESS] Dataset saved to: /tmp/ad_diffi_data/Breast_Cancer.csv\n",
            "[INFO] Available features: ['Age', 'Tumor Size', 'Regional Node Examined', 'Reginol Node Positive', 'Race_White', 'Marital_Married', 'T_Stage_T1', 'N_Stage_N0', 'Stage_II', 'Differentiate_High', 'Grade_Low', 'A_Stage_Regional', 'Estrogen_Positive', 'Progesterone_Positive']\n",
            "[INFO] Dataset: 4024 samples, 14 features\n",
            "[INFO] Feature types: 4 continuous, 10 binary\n",
            "======================================================================\n",
            "Running feature importance comparison...\n",
            "======================================================================\n",
            "Establishing noise baseline (RSO DIFFI) over 20 iterations...\n",
            "  Continuous (mean=1.0366, std=0.0067)\n",
            "  Binary      (mean=1.0690, std=0.0168)\n",
            "Running 20 iterations for feature importance comparison...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4025595036.py:234: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_outliers = np.where(cnt_outliers > 0, cfi_outliers / cnt_outliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:235: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_inliers = np.where(cnt_inliers > 0, cfi_inliers / cnt_inliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:234: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_outliers = np.where(cnt_outliers > 0, cfi_outliers / cnt_outliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:235: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_inliers = np.where(cnt_inliers > 0, cfi_inliers / cnt_inliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:234: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_outliers = np.where(cnt_outliers > 0, cfi_outliers / cnt_outliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:235: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_inliers = np.where(cnt_inliers > 0, cfi_inliers / cnt_inliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:234: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_outliers = np.where(cnt_outliers > 0, cfi_outliers / cnt_outliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:235: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_inliers = np.where(cnt_inliers > 0, cfi_inliers / cnt_inliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:234: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_outliers = np.where(cnt_outliers > 0, cfi_outliers / cnt_outliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:235: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_inliers = np.where(cnt_inliers > 0, cfi_inliers / cnt_inliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:234: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_outliers = np.where(cnt_outliers > 0, cfi_outliers / cnt_outliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:235: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_inliers = np.where(cnt_inliers > 0, cfi_inliers / cnt_inliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:234: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_outliers = np.where(cnt_outliers > 0, cfi_outliers / cnt_outliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:235: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_inliers = np.where(cnt_inliers > 0, cfi_inliers / cnt_inliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:234: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_outliers = np.where(cnt_outliers > 0, cfi_outliers / cnt_outliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:235: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_inliers = np.where(cnt_inliers > 0, cfi_inliers / cnt_inliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:234: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_outliers = np.where(cnt_outliers > 0, cfi_outliers / cnt_outliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:235: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_inliers = np.where(cnt_inliers > 0, cfi_inliers / cnt_inliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:234: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_outliers = np.where(cnt_outliers > 0, cfi_outliers / cnt_outliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:235: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_inliers = np.where(cnt_inliers > 0, cfi_inliers / cnt_inliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:234: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_outliers = np.where(cnt_outliers > 0, cfi_outliers / cnt_outliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:235: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_inliers = np.where(cnt_inliers > 0, cfi_inliers / cnt_inliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:234: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_outliers = np.where(cnt_outliers > 0, cfi_outliers / cnt_outliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:235: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_inliers = np.where(cnt_inliers > 0, cfi_inliers / cnt_inliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:234: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_outliers = np.where(cnt_outliers > 0, cfi_outliers / cnt_outliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:235: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_inliers = np.where(cnt_inliers > 0, cfi_inliers / cnt_inliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:234: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_outliers = np.where(cnt_outliers > 0, cfi_outliers / cnt_outliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:235: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_inliers = np.where(cnt_inliers > 0, cfi_inliers / cnt_inliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:234: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_outliers = np.where(cnt_outliers > 0, cfi_outliers / cnt_outliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:235: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_inliers = np.where(cnt_inliers > 0, cfi_inliers / cnt_inliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:234: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_outliers = np.where(cnt_outliers > 0, cfi_outliers / cnt_outliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:235: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_inliers = np.where(cnt_inliers > 0, cfi_inliers / cnt_inliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:234: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_outliers = np.where(cnt_outliers > 0, cfi_outliers / cnt_outliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:235: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_inliers = np.where(cnt_inliers > 0, cfi_inliers / cnt_inliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:234: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_outliers = np.where(cnt_outliers > 0, cfi_outliers / cnt_outliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:235: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_inliers = np.where(cnt_inliers > 0, cfi_inliers / cnt_inliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:234: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_outliers = np.where(cnt_outliers > 0, cfi_outliers / cnt_outliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:235: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_inliers = np.where(cnt_inliers > 0, cfi_inliers / cnt_inliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:234: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_outliers = np.where(cnt_outliers > 0, cfi_outliers / cnt_outliers, 0)\n",
            "/tmp/ipython-input-4025595036.py:235: RuntimeWarning: invalid value encountered in divide\n",
            "  fi_inliers = np.where(cnt_inliers > 0, cfi_inliers / cnt_inliers, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature Importance Comparison (Table S2)\n",
            "| Feature                | Type   |   Original_DIFFI |   AD_DIFFI_RSO_Z |   Rank_Original |   Rank_AD_DIFFI |   Rank_Change |\n",
            "|:-----------------------|:-------|-----------------:|-----------------:|----------------:|----------------:|--------------:|\n",
            "| A_Stage_Regional       | bin    |           1.0871 |          19.0167 |               2 |               1 |            -1 |\n",
            "| Estrogen_Positive      | bin    |           0.8188 |          17.2555 |              11 |               2 |            -9 |\n",
            "| Race_White             | bin    |           0.8516 |          13.739  |               8 |               3 |            -5 |\n",
            "| Progesterone_Positive  | bin    |           0.8705 |          13.0726 |               7 |               4 |            -3 |\n",
            "| Marital_Married        | bin    |           1.0404 |          12.4446 |               3 |               5 |             2 |\n",
            "| Differentiate_High     | bin    |           0.9939 |          12.3625 |               4 |               6 |             2 |\n",
            "| Reginol Node Positive  | cont   |           0.9451 |          12.1436 |               5 |               7 |             2 |\n",
            "| T_Stage_T1             | bin    |           1.2111 |          11.9103 |               1 |               8 |             7 |\n",
            "| Age                    | cont   |           0.8917 |          11.7106 |               6 |               9 |             3 |\n",
            "| Regional Node Examined | cont   |           0.8374 |          10.9226 |              10 |              10 |             0 |\n",
            "| Tumor Size             | cont   |           0.8512 |          10.0184 |               9 |              11 |             2 |\n",
            "| N_Stage_N0             | bin    |           0      |         -63.4849 |              13 |              13 |             0 |\n",
            "| Stage_II               | bin    |           0      |         -63.4849 |              13 |              13 |             0 |\n",
            "| Grade_Low              | bin    |           0      |         -63.4849 |              13 |              13 |             0 |\n",
            "======================================================================\n",
            "Performance Evaluation (IF AUC + Cox C-index)\n",
            "======================================================================\n",
            "[DEBUG] Cox: 4024 samples, 14 features\n",
            "[DEBUG] After variance filter: 11 features\n",
            "[DEBUG] After correlation filter: 10 features\n",
            "[SUCCESS] Cox C-index: 0.7226 (10 features)\n",
            "All 14 features:  IF AUC=0.6530, Cox C-index=0.7226\n",
            "[DEBUG] Cox: 4024 samples, 6 features\n",
            "[DEBUG] After variance filter: 6 features\n",
            "[SUCCESS] Cox C-index: 0.6950 (6 features)\n",
            "Original DIFFI top-6: IF AUC=0.6848, Cox C-index=0.6950\n",
            "[DEBUG] Cox: 4024 samples, 6 features\n",
            "[DEBUG] After variance filter: 6 features\n",
            "[SUCCESS] Cox C-index: 0.6690 (6 features)\n",
            "AD-DIFFI top-6:     IF AUC=0.6120, Cox C-index=0.6690\n",
            "\n",
            "Summary Table:\n",
            "| Method               |   IF AUC |   Cox C-index |\n",
            "|:---------------------|---------:|--------------:|\n",
            "| All Features         |   0.653  |        0.7226 |\n",
            "| Original DIFFI Top-6 |   0.6848 |        0.695  |\n",
            "| AD-DIFFI Top-6       |   0.612  |        0.669  |\n",
            "======================================================================\n",
            "Analysis complete.\n",
            "======================================================================\n",
            "[INFO] Files saved:\n",
            "  - breast_cancer_analysis_seed42.csv\n",
            "  - breast_cancer_performance_seed42.csv\n",
            "  - breast_cancer_metrics_seed42.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_62142455-ba87-4ee7-b94c-9dd509242e74\", \"breast_cancer_analysis_seed42.csv\", 732)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_111ccc30-0525-4765-be4e-2f49ce2b7127\", \"breast_cancer_performance_seed42.csv\", 113)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7167fa6c-bcb1-4a01-b4dc-88db4dd4355f\", \"breast_cancer_metrics_seed42.json\", 261)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Downloads started...\n"
          ]
        }
      ]
    }
  ]
}
