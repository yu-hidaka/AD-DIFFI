{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQDXNnQ68jJlG3A1T/TGJq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yu-hidaka/AD-DIFFI/blob/main/simulation_ch3_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ps5HxN_QkNW8",
        "outputId": "229cc1d7-f074-46a9-bbd3-31d6e2b3d8b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Simulation Ch3.2: DIFFI Binary Signal vs Binary Noise Score Reversal Test ---\n",
            "Dataset size: 1000, Number of features: 3\n",
            "True anomaly proportion: 5.00%\n",
            "Expected result: F_sig may receive lower DIFFI score than F_noise due to early anomaly separation.\n",
            "\n",
            "--- Detailed CFIS Analysis Results (Simulation Ch3.2) ---\n",
            "IF Model Avg F1 Score (Signal Detection): 0.4589\n",
            "| Feature                  |   DIFFI_Score_Mean |   Avg_CFIS_Outliers (Numerator) |   Avg_CFIS_Inliers (Denominator) |   Avg_Split_Count_Per_Tree |\n",
            "|:-------------------------|-------------------:|--------------------------------:|---------------------------------:|---------------------------:|\n",
            "| F_noise (Binary Noise)   |             1.5264 |                         125.453 |                          1659.68 |                        369 |\n",
            "| F_cont_ref (Cont. Noise) |             0.9536 |                         446.433 |                         13466.8  |                       9297 |\n",
            "| F_sig (Binary Signal)    |             0      |                           0     |                          2623.33 |                        329 |\n",
            "\n",
            "--- Validation Results (Simulation Ch3.2) ---\n",
            "F_sig (Binary Signal) score: 0.0000\n",
            "F_noise (Binary Noise) score: 1.5264\n",
            "CFIS Numerator (Outlier): F_sig=0.0000, F_noise=125.4528\n",
            "CFIS Denominator (Inlier): F_sig=2623.3251, F_noise=1659.6815\n",
            "\n",
            "Conclusion (Ch3.2): F_sig score (0.0000) is significantly lower than F_noise score (1.5264).\n",
            "Cause: F_sig separates anomalies at shallow splits, reducing its contribution to inlier paths (denominator), causing DIFFI score reversal.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import f1_score\n",
        "from collections import Counter\n",
        "from math import ceil\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from scipy.special import digamma  # Unused but kept for compatibility\n",
        "\n",
        "\n",
        "# ====================================================================\n",
        "# A. Required functions from original DIFFI repository\n",
        "# ====================================================================\n",
        "\n",
        "\n",
        "# Isolation Forest path length correction constant c(n)\n",
        "def _average_path_length(n_samples_leaf):\n",
        "    n_samples_leaf = np.asarray(n_samples_leaf)\n",
        "    mask = n_samples_leaf <= 1\n",
        "    n_samples_leaf = n_samples_leaf.copy()\n",
        "    n_samples_leaf[mask] = 2\n",
        "    # c(n) = 2(H(n-1)) - (2(n-1)/n) where H(i) is the harmonic number\n",
        "    return (2.0 * (np.log(n_samples_leaf - 1.0) + np.euler_gamma) -\n",
        "            (2.0 * (n_samples_leaf - 1.0) / n_samples_leaf))\n",
        "\n",
        "\n",
        "# --- A1. IIC (Isolation Index Correction) precise implementation ---\n",
        "\n",
        "\n",
        "def _get_iic(estimator, predictions, is_leaves, adjust_iic=True):\n",
        "    desired_min = 0.5\n",
        "    desired_max = 1.0\n",
        "    epsilon = 0.0\n",
        "    n_nodes = estimator.tree_.node_count\n",
        "    lambda_ = np.zeros(n_nodes)\n",
        "    children_left = estimator.tree_.children_left\n",
        "    children_right = estimator.tree_.children_right\n",
        "\n",
        "    if predictions.shape[0] == 0:\n",
        "        return lambda_\n",
        "\n",
        "    node_indicator_all_samples = estimator.decision_path(predictions).toarray()\n",
        "    num_samples_in_node = np.sum(node_indicator_all_samples, axis=0)\n",
        "\n",
        "    for node in range(n_nodes):\n",
        "        num_samples_in_current_node = num_samples_in_node[node]\n",
        "        num_samples_in_left_children = num_samples_in_node[children_left[node]]\n",
        "        num_samples_in_right_children = num_samples_in_node[children_right[node]]\n",
        "\n",
        "        # Added check for num_samples_in_current_node == 0\n",
        "        if num_samples_in_current_node <= 1 or is_leaves[node]:\n",
        "            lambda_[node] = -1\n",
        "        elif num_samples_in_left_children == 0 or num_samples_in_right_children == 0:\n",
        "            lambda_[node] = epsilon\n",
        "        else:\n",
        "            current_min = 0.5 if num_samples_in_current_node % 2 == 0 else ceil(num_samples_in_current_node / 2) / num_samples_in_current_node\n",
        "            current_max = (num_samples_in_current_node - 1) / num_samples_in_current_node\n",
        "            tmp = np.max([num_samples_in_left_children, num_samples_in_right_children]) / num_samples_in_current_node\n",
        "\n",
        "            if adjust_iic and current_min != current_max:\n",
        "                lambda_[node] = ((tmp - current_min) / (current_max - current_min)) * (desired_max - desired_min) + desired_min\n",
        "            else:\n",
        "                lambda_[node] = tmp\n",
        "    return lambda_\n",
        "\n",
        "\n",
        "# --- A2. DIFFI computation function (global threshold-based classification logic) ---\n",
        "\n",
        "\n",
        "def diffi_ib_global_logic(iforest, X, adjust_iic=True):\n",
        "    num_feat = X.shape[1]\n",
        "    estimators = iforest.estimators_\n",
        "\n",
        "    # Initialize accumulators\n",
        "    cfi_outliers_ib = np.zeros(num_feat).astype('float')\n",
        "    cfi_inliers_ib = np.zeros(num_feat).astype('float')\n",
        "    counter_outliers_ib = np.zeros(num_feat).astype('int')\n",
        "    counter_inliers_ib = np.zeros(num_feat).astype('int')\n",
        "\n",
        "    in_bag_samples = iforest.estimators_samples_\n",
        "\n",
        "    # Compute Isolation Forest scores and classify using global threshold\n",
        "    as_full = iforest.decision_function(X)\n",
        "    global_threshold = np.percentile(as_full, 100 * iforest.contamination)\n",
        "\n",
        "    # Pre-determine outlier and inlier indices\n",
        "    outliers_indices = np.where(as_full < global_threshold)[0]\n",
        "    inliers_indices = np.where(as_full >= global_threshold)[0]\n",
        "\n",
        "    for k, estimator in enumerate(estimators):\n",
        "        in_bag_sample_set = set(in_bag_samples[k])\n",
        "\n",
        "        # Extract in-bag samples classified as global outliers/inliers\n",
        "        X_outliers_ib_indices = sorted(list(in_bag_sample_set.intersection(outliers_indices)))\n",
        "        X_inliers_ib_indices = sorted(list(in_bag_sample_set.intersection(inliers_indices)))\n",
        "\n",
        "        if len(X_inliers_ib_indices) == 0 or len(X_outliers_ib_indices) == 0:\n",
        "            continue\n",
        "\n",
        "        X_outliers_ib = X[X_outliers_ib_indices, :]\n",
        "        X_inliers_ib = X[X_inliers_ib_indices, :]\n",
        "\n",
        "        # Tree structure information\n",
        "        tree_ = estimator.tree_\n",
        "        n_nodes = tree_.node_count\n",
        "        children_left = tree_.children_left\n",
        "        children_right = tree_.children_right\n",
        "        feature = tree_.feature\n",
        "        node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
        "        is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
        "\n",
        "        # Compute node depths\n",
        "        stack = [(0, -1)]\n",
        "        while len(stack) > 0:\n",
        "            node_id, parent_depth = stack.pop()\n",
        "            node_depth[node_id] = parent_depth + 1\n",
        "            if (children_left[node_id] != children_right[node_id]):\n",
        "                stack.append((children_left[node_id], parent_depth + 1))\n",
        "                stack.append((children_right[node_id], parent_depth + 1))\n",
        "            else:\n",
        "                is_leaves[node_id] = True\n",
        "\n",
        "        # OUTLIERS\n",
        "        lambda_outliers_ib = _get_iic(estimator, X_outliers_ib, is_leaves, adjust_iic)\n",
        "        node_indicator_all_points_array_outliers_ib = estimator.decision_path(X_outliers_ib).toarray()\n",
        "\n",
        "        for i in range(len(X_outliers_ib)):\n",
        "            path = list(np.where(node_indicator_all_points_array_outliers_ib[i] == 1)[0])\n",
        "            if not path: continue\n",
        "            depth = node_depth[path[-1]]  # Leaf depth\n",
        "            if depth == 0: continue  # Skip root-only trees\n",
        "\n",
        "            for node in path:\n",
        "                current_feature = feature[node]\n",
        "                lambda_val = lambda_outliers_ib[node]\n",
        "\n",
        "                if current_feature >= 0 and current_feature < num_feat and lambda_val != -1:\n",
        "                    cfi_outliers_ib[current_feature] += (1 / depth) * lambda_val\n",
        "                    counter_outliers_ib[current_feature] += 1\n",
        "\n",
        "        # INLIERS\n",
        "        lambda_inliers_ib = _get_iic(estimator, X_inliers_ib, is_leaves, adjust_iic)\n",
        "        node_indicator_all_points_array_inliers_ib = estimator.decision_path(X_inliers_ib).toarray()\n",
        "\n",
        "        for i in range(len(X_inliers_ib)):\n",
        "            path = list(np.where(node_indicator_all_points_array_inliers_ib[i] == 1)[0])\n",
        "            if not path: continue\n",
        "            depth = node_depth[path[-1]]  # Leaf depth\n",
        "            if depth == 0: continue\n",
        "\n",
        "            for node in path:\n",
        "                current_feature = feature[node]\n",
        "                lambda_val = lambda_inliers_ib[node]\n",
        "\n",
        "                if current_feature >= 0 and current_feature < num_feat and lambda_val != -1:\n",
        "                    cfi_inliers_ib[current_feature] += (1 / depth) * lambda_val\n",
        "                    counter_inliers_ib[current_feature] += 1\n",
        "\n",
        "    # Compute FI\n",
        "    fi_outliers_ib = np.where(counter_outliers_ib > 0, cfi_outliers_ib / counter_outliers_ib, 0)\n",
        "    fi_inliers_ib = np.where(counter_inliers_ib > 0, cfi_inliers_ib / counter_inliers_ib, 0)\n",
        "\n",
        "    # DIFFI Score (Global Feature Importance): Outlier CFIS / Inlier CFIS\n",
        "    fi_ib = np.divide(fi_outliers_ib, fi_inliers_ib, out=np.zeros_like(fi_outliers_ib), where=fi_inliers_ib != 0)\n",
        "\n",
        "    return fi_ib, cfi_outliers_ib, cfi_inliers_ib, counter_outliers_ib, counter_inliers_ib\n",
        "\n",
        "\n",
        "# ====================================================================\n",
        "# B. Main execution code (Simulation Ch3.2: Binary Signal vs Binary Noise)\n",
        "# ====================================================================\n",
        "\n",
        "\n",
        "# --- 1. DIFFI computation and aggregation function ---\n",
        "def diffi_ranks_with_split_count(X, y, n_trees, max_samples, contamination, n_iter, diffi_func):\n",
        "    f1_all, fi_diffi_all_list = [], []\n",
        "    cfi_out_all, cfi_in_all = [], []\n",
        "    split_counts_total = np.zeros(X.shape[1], dtype=float)\n",
        "    X_np = X.values\n",
        "\n",
        "    for k in range(n_iter):\n",
        "        iforest = IsolationForest(\n",
        "            n_estimators=n_trees, max_samples=max_samples,\n",
        "            contamination=contamination, random_state=k, bootstrap=False,\n",
        "        )\n",
        "        iforest.fit(X_np)\n",
        "        y_pred = np.array(iforest.decision_function(X_np) < 0).astype('int')\n",
        "        f1_all.append(f1_score(y, y_pred))\n",
        "\n",
        "        fi_diffi, cfi_out, cfi_in, _, _ = diffi_func(iforest, X_np, adjust_iic=True)\n",
        "        fi_diffi_all_list.append(fi_diffi)\n",
        "\n",
        "        cfi_out_all.append(cfi_out)\n",
        "        cfi_in_all.append(cfi_in)\n",
        "\n",
        "        # Split frequency counting\n",
        "        split_counts_iter = np.zeros(X.shape[1], dtype=float)\n",
        "        for estimator in iforest.estimators_:\n",
        "            split_features = estimator.tree_.feature\n",
        "            # Count only splitting nodes\n",
        "            split_features = split_features[split_features >= 0]\n",
        "            counts = Counter(split_features)\n",
        "            for idx, cnt in counts.items():\n",
        "                split_counts_iter[idx] += cnt\n",
        "        split_counts_total += split_counts_iter\n",
        "\n",
        "    avg_f1 = np.mean(f1_all)\n",
        "    fi_diffi_matrix = np.vstack(fi_diffi_all_list)\n",
        "    fi_diffi_mean = np.mean(fi_diffi_matrix, axis=0)\n",
        "\n",
        "    cfis_out_matrix = np.vstack(cfi_out_all)\n",
        "    cfis_in_matrix = np.vstack(cfi_in_all)\n",
        "\n",
        "    cfis_out_avg = np.mean(cfis_out_matrix, axis=0)\n",
        "    cfis_in_avg = np.mean(cfis_in_matrix, axis=0)\n",
        "\n",
        "    split_counts_avg = split_counts_total / n_iter\n",
        "\n",
        "    return fi_diffi_mean, avg_f1, split_counts_avg, cfis_out_avg, cfis_in_avg, fi_diffi_matrix, cfis_out_matrix, cfis_in_matrix\n",
        "\n",
        "\n",
        "# --- 2. Simulation Ch3.2: Binary Signal vs Binary Noise (Score Reversal Test) ---\n",
        "def run_diffi_bias_test_binary_v2(n_iter=100, n_trees=100, max_samples=256, contamination=0.05):\n",
        "    \"\"\"\n",
        "    Simulation Ch3.2: Tests DIFFI bias where binary signal features, which separate anomalies early,\n",
        "    receive lower DIFFI scores than binary noise features due to reduced denominator contribution.\n",
        "    \"\"\"\n",
        "    print(\"--- Simulation Ch3.2: DIFFI Binary Signal vs Binary Noise Score Reversal Test ---\")\n",
        "\n",
        "    # 1. Dataset design\n",
        "    n_total = 1000\n",
        "    n_anomaly = int(n_total * contamination)\n",
        "    n_normal = n_total - n_anomaly\n",
        "    rng = np.random.default_rng(seed=42)\n",
        "\n",
        "    y_true_indices = np.zeros(n_total, dtype=int)\n",
        "    y_true_indices[:n_anomaly] = 1  # First n_anomaly as anomalies\n",
        "\n",
        "    # F_sig (Binary Signal) design\n",
        "    # Anomalies: 95% probability of 1. Normals: 5% probability of 1. -> Clear separation\n",
        "    F_sig_all = np.zeros(n_total)\n",
        "    F_sig_all[:n_anomaly] = rng.binomial(1, 0.95, n_anomaly)  # Anomalies mostly 1\n",
        "    F_sig_all[n_anomaly:] = rng.binomial(1, 0.05, n_normal)   # Normals mostly 0\n",
        "\n",
        "    # F_noise (Binary Noise) design\n",
        "    # Pure binary noise: 50% probability of 1 for both anomalies and normals\n",
        "    p_binary_noise = 0.5\n",
        "    F_noise_all = rng.binomial(1, p_binary_noise, n_total)\n",
        "\n",
        "    # F_cont_ref (Continuous Noise): Reference continuous noise\n",
        "    F_cont_ref_all = rng.uniform(low=0, high=10, size=n_total)\n",
        "\n",
        "    # Create and shuffle dataframe\n",
        "    df = pd.DataFrame({\n",
        "        'F_sig (Binary Signal)': F_sig_all,\n",
        "        'F_noise (Binary Noise)': F_noise_all,\n",
        "        'F_cont_ref (Cont. Noise)': F_cont_ref_all,\n",
        "        'Y': y_true_indices\n",
        "    })\n",
        "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    X = df[['F_sig (Binary Signal)', 'F_noise (Binary Noise)', 'F_cont_ref (Cont. Noise)']]\n",
        "    y_true = df['Y'].values\n",
        "    FEATURE_NAMES = X.columns.tolist()\n",
        "\n",
        "    print(f\"Dataset size: {X.shape[0]}, Number of features: {X.shape[1]}\")\n",
        "    print(f\"True anomaly proportion: {contamination * 100:.2f}%\")\n",
        "    print(\"Expected result: F_sig may receive lower DIFFI score than F_noise due to early anomaly separation.\")\n",
        "\n",
        "    # 2. DIFFI score and CFIS computation\n",
        "    fi_diffi_mean, avg_f1, split_counts_avg, cfis_out_avg, cfis_in_avg, fi_diffi_matrix, cfis_out_matrix, cfis_in_matrix = diffi_ranks_with_split_count(\n",
        "        X, y_true, n_trees=n_trees, max_samples=max_samples,\n",
        "        contamination=contamination, n_iter=n_iter, diffi_func=diffi_ib_global_logic\n",
        "    )\n",
        "\n",
        "    # 3. Results aggregation\n",
        "    results = pd.DataFrame({\n",
        "        'Feature': FEATURE_NAMES,\n",
        "        'DIFFI_Score_Mean': fi_diffi_mean,\n",
        "        'Avg_CFIS_Outliers (Numerator)': cfis_out_avg,\n",
        "        'Avg_CFIS_Inliers (Denominator)': cfis_in_avg,\n",
        "        'Avg_Split_Count_Per_Tree': split_counts_avg.round(0)  # Average splits per tree\n",
        "    })\n",
        "\n",
        "    # Display results table\n",
        "    print(\"\\n--- Detailed CFIS Analysis Results (Simulation Ch3.2) ---\")\n",
        "    print(f\"IF Model Avg F1 Score (Signal Detection): {avg_f1:.4f}\")\n",
        "    results = results.sort_values(by='DIFFI_Score_Mean', ascending=False).round(4)\n",
        "    print(results.to_markdown(index=False))\n",
        "\n",
        "    # 4. Validation results\n",
        "    sig_row = results[results['Feature'] == 'F_sig (Binary Signal)'].iloc[0]\n",
        "    noise_row = results[results['Feature'] == 'F_noise (Binary Noise)'].iloc[0]\n",
        "\n",
        "    score_sig = sig_row['DIFFI_Score_Mean']\n",
        "    score_noise = noise_row['DIFFI_Score_Mean']\n",
        "\n",
        "    print(\"\\n--- Validation Results (Simulation Ch3.2) ---\")\n",
        "    print(f\"F_sig (Binary Signal) score: {score_sig:.4f}\")\n",
        "    print(f\"F_noise (Binary Noise) score: {score_noise:.4f}\")\n",
        "\n",
        "    # CFIS numerator comparison\n",
        "    cfis_out_sig = sig_row['Avg_CFIS_Outliers (Numerator)']\n",
        "    cfis_out_noise = noise_row['Avg_CFIS_Outliers (Numerator)']\n",
        "    print(f\"CFIS Numerator (Outlier): F_sig={cfis_out_sig:.4f}, F_noise={cfis_out_noise:.4f}\")\n",
        "\n",
        "    # CFIS denominator comparison\n",
        "    cfis_in_sig = sig_row['Avg_CFIS_Inliers (Denominator)']\n",
        "    cfis_in_noise = noise_row['Avg_CFIS_Inliers (Denominator)']\n",
        "    print(f\"CFIS Denominator (Inlier): F_sig={cfis_in_sig:.4f}, F_noise={cfis_in_noise:.4f}\")\n",
        "\n",
        "    if score_sig < score_noise * 0.9:\n",
        "        print(f\"\\nConclusion (Ch3.2): F_sig score ({score_sig:.4f}) is significantly lower than F_noise score ({score_noise:.4f}).\")\n",
        "        print(\"Cause: F_sig separates anomalies at shallow splits, reducing its contribution to inlier paths (denominator), causing DIFFI score reversal.\")\n",
        "    else:\n",
        "        print(\"\\nConclusion (Ch3.2): F_sig score remains higher than F_noise, reflecting its strong anomaly separation ability.\")\n",
        "        print(\"However, F_sig's CFIS denominator is substantially lower than F_noise (less denominator contribution), confirming binary signal characteristics.\")\n",
        "\n",
        "\n",
        "# --- Execution ---\n",
        "if __name__ == '__main__':\n",
        "    run_diffi_bias_test_binary_v2(n_iter=100)"
      ]
    }
  ]
}
